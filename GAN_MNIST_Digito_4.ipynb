{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj/dofmaGUMmbVIYWFSuT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dede0702/mnist-digit-4-gan/blob/main/GAN_MNIST_Digito_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ```\n",
        "üß© Etapa 1: Instalar depend√™ncias\n",
        " ```"
      ],
      "metadata": {
        "id": "jR-GcI5rMkdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PwRYa4Xe7x0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12691f5-7027-4801-beb2-e6a45db38b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ```\n",
        "üì¶ Etapa 2: Importar bibliotecas\n",
        " ```"
      ],
      "metadata": {
        "id": "IjCQQAIqM3Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets # Alterado para torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fk1HIGN-M6-h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "üìÅ Etapa 3: Carregar apenas os d√≠gitos 4 do MNIST (usando torchvision)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2AU0xw8fM26M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST4Dataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # Carregar o dataset MNIST usando torchvision\n",
        "        mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
        "\n",
        "        # Filtrar para incluir apenas os d√≠gitos '4'\n",
        "        idx = mnist_trainset.targets == 4\n",
        "        data_4_filtered = mnist_trainset.data[idx] # Tensor de formato (N, 28, 28), tipo uint8\n",
        "\n",
        "        # Converter para float, normalizar para [-1, 1] e adicionar dimens√£o de canal\n",
        "        # Imagens s√£o (H, W), precisamos de (C, H, W) para Conv2d, ent√£o (1, 28, 28)\n",
        "        data_normalized = data_4_filtered.float() / 255.0  # Escala para [0, 1]\n",
        "        self.data = (data_normalized * 2.0) - 1.0      # Escala para [-1, 1]\n",
        "        self.data = self.data.unsqueeze(1)   # Adiciona dimens√£o de canal: (N, 1, 28, 28)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "dataset = MNIST4Dataset()\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "cBBCRV56N1d5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar algumas imagens do dataset para confirmar\n",
        "print(f\"N√∫mero de amostras do d√≠gito 4: {len(dataset)}\")\n",
        "fig, axs = plt.subplots(1, 5, figsize=(10, 2))\n",
        "for i in range(5):\n",
        "    img = dataset[i].squeeze().numpy() # Remove canal, converte para numpy\n",
        "    axs[i].imshow(img, cmap='gray')\n",
        "    axs[i].set_title(f\"Amostra {i+1}\")\n",
        "    axs[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "mj0fryktN5ZT",
        "outputId": "074466ca-b29e-4316-c6a8-dac307448262"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de amostras do d√≠gito 4: 5842\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACvCAYAAACVbcM3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHaxJREFUeJzt3Xt0TWf6wPHnIHEdl0qauFSIS9sR1LUu/SlKKOPSShC0UkNRt5kOuhhTVEdbRbWuoy5BUkob0rJmCGPMcq3LlIUyiCCoSyOkkkiwf3/0J/3t826yz0nec3L5ftay1rxP3r33k+TpyXlmn3e/DsMwDAEAAACAPFbM2wkAAAAAKJxoNgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtKDZAAAAAKAFzQYAAAAALWg2AAAAAGiRb5uNhQsXisPhkOeff97bqdgyY8YM2bhxo0evuWjRIgkPD5caNWqIw+GQyMhIj16/MKP+Hu/ixYsybdo0adGihVSqVEn8/PykXbt2sm3bNo/lUNhRg4+Xnp4uv//97yUkJEQqVKgg5cqVk0aNGsmnn34qWVlZHsujsKL+XLNr1y5xOBzicDjkxo0bXsujsKD+cvaw3pz/ffjhhx7Nww6HYRiGt5Ow0qZNG7l8+bIkJibK6dOnpU6dOt5O6bHKlSsnYWFhEhUV5bFr1qxZU1JTU6VFixaybds2GTBggEevX5hRf483f/58mTBhgvTq1UvatGkj9+7dk1WrVsnhw4dl+fLl8sYbb3gkj8KMGny85ORk6dq1q7Rt21Zq1qwpxYoVkz179kh0dLT069dPvvjiC4/kUVhRf/Y9ePBAmjZtKqdPn5Y7d+7I9evXxc/Pz+N5FCbUX84cDod06tRJXn/9dVO8cePGUr9+fY/lYYuRDyUkJBgiYsTGxhr+/v7G1KlTvZ1SjsqWLWsMGjTI1tyff/45T66ZmJhoPHjwwOXr4/Gov5wdO3bMuH79uimWkZFhPPPMM0b16tVzff6ijhp036hRowwRMa5cuaLtGoUd9eeaRYsWGZUrVzbGjh1riIjy2gjXUH/2iIgxcuTIPDmXbvnyY1QxMTFSqVIl6datm4SFhUlMTIwyJzExURwOh8yaNUsWLFggwcHBUqZMGQkNDZWLFy+KYRgyffp0qV69upQuXVp69uwpycnJynkWLlwo9evXl5IlS0rVqlVl5MiRkpKSYppz+vRp6d27twQGBkqpUqWkevXq0q9fP7l165aI/NJd3rlzR1auXJl9G+vhR5qmTp0qDodDTpw4If3795dKlSrJCy+8ICIiR48elcjISAkODpZSpUpJYGCgDB48WH766SdbP6egoCBxOBwu/GRhB/WXc/3Vr19f+X/uSpYsKV27dpWkpCRJTU2186PGI1CD9l4DrdSsWVNERPkeYB/1Z7/+kpOTZfLkyfLee+9JxYoVbR+HR6P+XHv9S09Pl4yMDJeO8bQS3k7ASkxMjLz66qvi6+srERERsmjRIjlw4IA0b97ccm5mZqaMHj1akpOTZebMmdKnTx/p0KGD/Otf/5J33nlHzpw5I/PmzZNx48bJ8uXLs4+dOnWqTJs2TTp27CgjRoyQU6dOZV9r9+7d4uPjI5mZmdK5c2e5e/eujB49WgIDA+XSpUuyadMmSUlJkQoVKsjq1atlyJAh0qJFC3nzzTdFRKR27dqmPMPDw6Vu3boyY8YMMf7vk2vx8fGSkJAgb7zxhgQGBsrx48dlyZIlcvz4cdm3bx+NhJdQf+7X348//ihlypSRMmXKuHwsfkUN2q/BzMxMuX37tqSnp8vBgwdl1qxZEhQUlO8/dpGfUX/26+8vf/mLBAYGyrBhw2T69Om5+bHj/1B/9usvKipKFi5cKIZhyLPPPiuTJ0+W/v375+bHr4eX7qg80sGDBw0RMeLj4w3DMIwHDx4Y1atXN8aOHWuad+7cOUNEDH9/fyMlJSU7PnHiRENEjEaNGhlZWVnZ8YiICMPX19fIyMgwDMMwrl27Zvj6+hqhoaHG/fv3s+fNnz/fEBFj+fLlhmEYxn/+8x9DRIz169c/Nu9H3UKbMmWKISJGRESE8rW0tDQltmbNGkNEjH//+9+PvZ7d68M11J979WcYhnH69GmjVKlSxmuvvebysfgVNehaDT6c//Bfs2bNjKNHj9o6Firqz379HTlyxChevLixZcsW07X4GJX7qD/79de6dWtj7ty5RlxcnLFo0SIjJCTEEBFj4cKFOR7rafnuY1QxMTESEBAg7du3F5Ffbk/17dtX1q5dK/fv31fmh4eHS4UKFbLHD59cMHDgQClRooQpnpmZKZcuXRIRkW3btklmZqb84Q9/kGLFfv0xDB06VMqXLy+bN28WEck+95YtWyQtLc3t72v48OFKrHTp0tn/OyMjQ27cuCEtW7YUEZHDhw+7fS24j/pzr/7S0tIkPDxcSpcunS+fhFGQUIOu1WD79u0lPj5e1q9fL8OHDxcfHx+5c+eO23kWddSf/fobM2aMvPzyyxIaGup2XjCj/uzX3+7du2Xs2LHSo0cPGT58uBw6dEhCQkJk0qRJkp6e7nauOuSrZuP+/fuydu1aad++vZw7d07OnDkjZ86ckeeff16uXr0q27dvV46pUaOGafywMJ566inL+M2bN0VE5Pz58yIi8vTTT5vm+fr6SnBwcPbXa9WqJW+//bYsXbpU/Pz8pHPnzrJgwYLsz+rZVatWLSWWnJwsY8eOlYCAACldurT4+/tnz3P1/Mg96s+9+rt//77069dPTpw4IV999ZVUrVrVpdzwK2rQ9RoMCAiQjh07SlhYmCxatEh+97vfSadOneTHH390KT9Qf67U35dffil79uyR2bNnu5QHHo36y917QF9fXxk1apSkpKTIoUOHXD5ep3zVbPzzn/+UK1euyNq1a6Vu3brZ//r06SMiYrlIqHjx4pbnelTccONJv7Nnz5ajR49md4tjxoyR+vXrS1JSku1z/P8O9qE+ffrI559/LsOHD5fY2FjZunWr/OMf/xCRXx6lB8+i/tyrv6FDh8qmTZskKipKOnToYPs4qKjB3L8GhoWFyc8//yxxcXFuHV+UUX/262/8+PESHh4uvr6+kpiYKImJidkLiy9evCiXL1+2/w1CRKi/vHj9e9hkWS2G96Z8tUA8JiZGnnzySVmwYIHytdjYWNmwYYMsXrzY8pfmqqCgIBEROXXqlAQHB2fHMzMz5dy5c9KxY0fT/AYNGkiDBg1k8uTJsmfPHmnTpo0sXrxY3n//fRERlxfT3rx5U7Zv3y7Tpk2Td999Nzt++vRpd78l5BL153r9jR8/XlasWCFz586ViIgIl46FihrM/Wvgw48PcHfYddSf/fq7ePGifPHFF5b7uTRp0kQaNWok33//vUs5FXXUX+5f/xISEkRExN/fP1fnyWv5ptlIT0+X2NhYCQ8Pl7CwMOXrVatWlTVr1sg333wjffv2zfX1OnbsKL6+vvLZZ59Jly5dsgtl2bJlcuvWLenWrZuIiNy+fVvKlClj+uxfgwYNpFixYnL37t3sWNmyZV161OLDrtu5y547d66b3xFyg/r7hSv19/HHH8usWbNk0qRJMnbsWNvHwRo1+Au7NXjjxg2pXLmy8kd+6dKlIiLSrFkz27mA+nvIbv1t2LBBia1du1a+/PJLWbVqlVSvXt12LqD+HrJbf9evX1caitTUVJk7d674+flJ06ZNbefiCfmm2fjmm28kNTVVevToYfn1li1bir+/v8TExORJofn7+8vEiRNl2rRp0qVLF+nRo4ecOnVKFi5cKM2bN5eBAweKyC+39UaNGiXh4eFSr149uXfvnqxevVqKFy8uvXv3zj5f06ZNZdu2bTJnzhypWrWq1KpVK3uhkpXy5ctL27ZtZebMmZKVlSXVqlWTrVu3yrlz52x/D99++60cOXJERESysrLk6NGj2V12jx49pGHDhu78aIok6s+1+tuwYYNMmDBB6tatK88++6xER0ebvt6pUycJCAhw4ydTdFGDrtVgdHS0LF68WHr16iXBwcGSmpoqW7Zskfj4eOnevTsf6XMR9eda/fXq1UuJPbyT8fLLL7ODuIuoP9fqb8GCBbJx40bp3r271KhRQ65cuSLLly+XCxcuyOrVq8XX1zd3P6C85q3HYDnr3r27UapUKePOnTuPnBMZGWn4+PgYN27cyH7s2ccff2yas2PHDsvHlK1YscIQEePAgQOm+Pz5841nnnnG8PHxMQICAowRI0YYN2/ezP56QkKCMXjwYKN27dpGqVKljCeeeMJo3769sW3bNtN5Tp48abRt29YoXbq0ISLZj0B73KPwkpKSjFdeecWoWLGiUaFCBSM8PNy4fPmyISLGlClTcvyZDRo0yPTIx///b8WKFTkej19Rf67V38PzPurfjh07Hns8VNSgazV44MABIzw83KhRo4ZRsmRJo2zZskaTJk2MOXPmmB55CXuoP9f/Bjvj0bfuo/5cq7+tW7canTp1MgIDAw0fHx+jYsWKRmhoqLF9+/bHHuctDsNwY7UMAAAAAOQgXz2NCgAAAEDhQbMBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtLC9qZ+rW7GjaPDUk5OpP1jx5JO7qUFY4TUQ3kT9wZvs1h93NgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtKDZAAAAAKAFzQYAAAAALWg2AAAAAGhBswEAAABAC5oNAAAAAFrQbAAAAADQgmYDAAAAgBY0GwAAAAC0oNkAAAAAoAXNBgAAAAAtaDYAAAAAaEGzAQAAAECLEt5OAEDhsH37diXmcDiUWIcOHTyRDvKhevXqKbHFixcrsQEDBiixK1euaMkJAKAXdzYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANCCBeIFxEsvvWQax8TEKHNefPFFJXbq1CltOaHo+uSTT5RY69atldiqVas8kU6+9pvf/EaJlStXTondunVLiaWlpWnJyVu6du2qxNq2bavEhgwZosQ++OAD0/jevXt5lxgAQBvubAAAAADQgmYDAAAAgBY0GwAAAAC0oNkAAAAAoIVXFohbLQisXLmyEtuwYYMn0ikQmjdvbhofOHDAS5mgKPrwww9N4+HDhytzsrKylJjVruJFzYQJE5TYxIkTldj48eOVmNVC/ILs4MGDtuZNmTJFia1Zs8Y0PnPmTJ7khKKjRo0aSmzv3r1KrHPnzkrs2LFjWnICigLubAAAAADQgmYDAAAAgBY0GwAAAAC08MqajXbt2imxunXrKrGiumajWDG1B6xVq5ZpHBQUpMxxOBzackLR1rJlS9PYx8dHmbNr1y4ltm7dOm05FTZW6xQSEhJM47i4OE+lo0VgYKC3U4CX1KtXT4llZGSYxhcuXNCaw6JFi5RYZmamEktNTdWaB4qG3/72t6ax1Vq9iIgIJea8ibOIyM6dO/MuMS/gzgYAAAAALWg2AAAAAGhBswEAAABAC5oNAAAAAFp4ZYH466+/rsSsNtYpqqpUqaLEhg4dahpHR0crc06ePKktJ+hntdnln//8ZyVmtaAsOTk5z/KwOn9ISIhpfPbsWWXOuHHj8iyHoqhcuXJKbMWKFaZxaGioMsfuRnne4Pw9vf32226fKzw83DT+4IMP3D4X9HrllVeU2MqVK5WY80MR8noTS+cHW3Ts2FGZ47xhqYjI+fPn8zQPFFwBAQFKrGzZskrM+WEeIiL79+/P8Tir18S8XAzu/LopIrJ+/fo8O79d3NkAAAAAoAXNBgAAAAAtaDYAAAAAaEGzAQAAAEALrywQt9ohG79aunRpjnNOnz7tgUzgSUuWLFFidevWVWLOu5KKWO/e7a5JkyYpscqVK5vGzg8sEBE5cuRInuVQmCQmJrp9bPny5U3jadOmKXMGDhyoxG7evOn2NfNSnTp1TOMWLVp4KRN40oABA5TYxo0blVheLwh31qtXL9O4RAn1Lc/XX3+tNQcUHFb1sWbNGiVWu3ZtJRYUFKTEnB+QsXXrVmXOsmXLXEnRZWXKlNF6frt41w8AAABAC5oNAAAAAFrQbAAAAADQgmYDAAAAgBbaF4g3bNhQiVntyIhfVahQIcc58fHxHsgEnpSWlqbEDMNQYqVKlcqzaz733HNKzGqh24MHD7TlUNhFRUUpsapVqyox592UrXTu3FmJ9e7dW4nZeciEJ1y7ds00ttplNzg42Na5vLHrLdzTpk0bJbZ69WqP5+H835nD4fB4Dsi/fH19TePo6GhlTrt27ZTY3r17bc1z/vv93nvvKXNSU1NzyLJw4M4GAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABaaF8g3rVrVyVWunRp3ZctMKwWy9eqVSvH4y5duqQjHXjQ9OnTTeMGDRooc3744Qcl5u5O3WXLllVi77zzjhKz2nF03759pvFXX33lVg5F0f3795XYZ599psSsdl123oHbysiRI5XYhg0blNhPP/2U47ny2pNPPmka210MjoLD6mEHVg+QsHrYhW7OD0+4c+eOMicjI8NT6cCLrN53Tpo0yTQOCwtT5hw+fFiJvfrqq0osIiIixxzOnz+f45y8lpyc7PFrWuHOBgAAAAAtaDYAAAAAaEGzAQAAAEAL7Ws2nn76aVvzjh8/rjmT/GnWrFlKzGodx3//+1/TuKhsBFNYPPXUU0ps6NChpvG9e/eUOaNGjVJi169fdyuHOXPmKLHw8HAldvnyZSVmtUkX3Hfr1i0ltnv3biVmZ82G1Vofq3pzd82G88ZXIiLDhg2zdaxVfaFwsXq9uHnzphKzWgtWsmRJ0/ju3bt5l5ion9P//vvvlTlnz57NMS+RvM8N+li9Zi1fvlyJ9e3b1zR2fp8lIjJmzBglZrU5pNWGfRcvXjSNf/75ZzVZzb799luPX9MKdzYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANBC+wJxuw4cOODtFHKlfPnySqxLly6m8cCBA5U5oaGhts7vvAFcSkqK/eTgUSEhIUrMapM1Pz8/03jevHnKnJ07d7qdx7hx40zjyMhIW8f99a9/dfuacN/evXuV2KBBg9w6V6tWrZSY1eLY1q1bP3YsIlKuXDklNnnyZLfysstqM0urRcfIn6w2/fzTn/6kxJw3fZw4caIyJyEhIc/ystpUctu2bUpsxowZSiw+Pj7P8oBeVu+rnBeDW/nuu++UWLVq1ZRYr169lJjV66Tz+XLzvu25554zjevWravM2bVrlxK7cuWK29fMS9zZAAAAAKAFzQYAAAAALWg2AAAAAGhBswEAAABAC4dhGIatiRY7JtqxYsUKJWa16NFq8c769evdumajRo2UmFX+HTt2NI2rV6+uzLHaiXLAgAFKrFgxtW9LT083jffv36/Madu2rRIrW7asEnNedHzy5ElljjfYLJ9cc7f+8lKJEurzFKwW/S9btkyJWdXHgwcPTGOrhyTExcUpMaudwJ944gkltnHjRtO4cePGypzo6GglNnjwYCWWX3mq/kS8U4OrV682jfv37+/xHOzUrie8+eabprHVf2feUJReA+2qVKmSErP6fTkvtLX6HtetW6fEMjIylJjV4u8XXnjBNLb6XVktXP/kk0+UWH5F/amKFy+uxJYuXarE3H0Ah12XLl0yjTdt2mTruBdffFGJ1alTxzS2ej/SvXt3JbZ582Zb13SX3frjzgYAAAAALWg2AAAAAGhBswEAAABAC5oNAAAAAFpoXyC+cOFCJTZs2DAlZrWz4oULF9y6ZsOGDZWYVf737t0zjdPS0pQ5J06cUGJWC70PHjyoxJx3f7569aoyJykpSYlZLa6zWqieHxSlxWlWi8GjoqJsHWuV/5kzZ0zj2rVr2zqXVa1Z7XJapUoV0/j69es5ziloCvsCceddY61+97pZfd+e/Lk/5PywkaFDh3o8BytF6TUwN6wW7fbp08c0DgsLU+bUqlXL1vmt/m4GBQWZxj179lTm/P3vf1dizu8N8jPqz56SJUsqsS5dupjGzZo1U+ZY/W2NjIy0dU3n93e5+V2dPXvWND5+/LgyZ/78+Urs1KlTbl/TDhaIAwAAAPAqmg0AAAAAWtBsAAAAANCCZgMAAACAFuoWhHnsrbfeUmLnz59XYq1bt86za1otLHfeTVlE5IcffjCN9+3bl2c5WHHeAVdExN/fX4klJCRozQP2OO9q77xAVUQkKytLiVk97MBq5+ebN2+axrNnz1bmWO0karWIzc4iXj8/P2XOxYsXlVi7du2UmPPiNBQdzg8yELFeFGi1U+2tW7dM43fffTfvEkOBcv/+fSW2Zs2ax45d8dprrymxlStXmsbfffedMqcgLQaH++7evavE4uLiHjsWEZkyZYqt8y9YsECJjR492mZ2+nTu3FmJbdmyxeN5cGcDAAAAgBY0GwAAAAC0oNkAAAAAoIX2NRtWPvroI29c1uteeuklW/O+/vprzZnADufNJ63WAr3//vtKzGpthx1Wn+/829/+psRatWrl1vmt1nXs2LFDibE+o3BKTk5WYs41bbVuKDefo3felJA1G9AlODjY2ymggAsICFBiEydOVGIHDhxQYvlhfYaV/PL3nDsbAAAAALSg2QAAAACgBc0GAAAAAC1oNgAAAABo4ZUF4ni8DRs2eDsFiLrBT2xsrDLHalM8d1ltuhcSEmLr2IiICCV27NixHI9LSkqydX54h/MGn6tWrVLmWC2Mdd6wVMR60yk7NZJfhIaGmsaVKlVS5jhvlInCqWTJkkqse/fuSsy5vm/fvq0tJxR8bdu2VWK+vr5KrCA9xMdqU1Zv4M4GAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABasEAceIRPP/1U6/krVKhgGoeHhytzypcvr8SsdgRdt25d3iWGfMN5QevgwYO9lIn3VatWzTS2WriJosHq4QCNGzdWYh999JFpnJ6eri0nFDzlypUzjYcPH67MuXTpkhKLiorSlVKhxZ0NAAAAAFrQbAAAAADQgmYDAAAAgBY0GwAAAAC0YIG4lzkcDiVWr149JbZv3z5PpAMPeuutt0zjESNGKHOuXbumxDp06KAtJyAvpaSkmMZXrlxR5lSpUsWtc8+YMUOJDRs2TIndu3fPrfMj/+rWrZuteQVpp2d43tChQ03j9u3bK3Ps/l3G43FnAwAAAIAWNBsAAAAAtKDZAAAAAKAFaza8zDAMJVasGD1gYRMUFKTEhgwZYhpb1cKSJUuUWFJSUt4lBmiUmJhoGoeFhSlzYmNjlVhAQECO5x40aJASGzNmjBJjzUbh06RJE1vzDh06pDkTFBQhISFK7I9//KNpHBcXp8xZuXKltpyKEt7VAgAAANCCZgMAAACAFjQbAAAAALSg2QAAAACgBQvE86FWrVopsaioKM8ngjwTHx+vxJwXjUdHRytzpkyZoi0nwNP279+vxHr27KnENm3apMT8/PxyPH+zZs2U2M6dO21mh/yoUaNGSsxqo7Xdu3d7Ih0UUFYbfl69etU0njVrljInIyNDW05FCXc2AAAAAGhBswEAAABAC5oNAAAAAFrQbAAAAADQggXiXuZwOLydAjxgxYoVSmz69OmmsdXupUBhd/DgQSXmvLOviMj48eNN482bN9s6Fwq2SpUqKTHDMJQYv3s8VLVqVSU2aNAgJbZkyRLTmIcM6MOdDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtHAYViutrCaykDnXIiMjldjy5cuV2Oeff67ErHa/zA9slk+uUX+w4qn6E6EGYY3XQL1mzpypxKz+ltauXVuJpaam6kgpX6H+VM4PXxERqVevnhIbPXq0aXzt2jVtORVWduuPOxsAAAAAtKDZAAAAAKAFzQYAAAAALWg2AAAAAGjBAnHkCovT4E0sEIe38Rqol9UC8VatWimx//mf//FEOvlOUa+/ypUrK7ETJ04osX79+imxHTt2aMmpKGGBOAAAAACvotkAAAAAoAXNBgAAAAAtWLOBXCnqnxeFd7FmA97GayC8qajXX2xsrBKzWosxb948T6RT5LBmAwAAAIBX0WwAAAAA0IJmAwAAAIAWNBsAAAAAtGCBOHKlqC9Og3exQBzexmsgvIn6gzexQBwAAACAV9FsAAAAANCCZgMAAACAFjQbAAAAALSwvUAcAAAAAFzBnQ0AAAAAWtBsAAAAANCCZgMAAACAFjQbAAAAALSg2QAAAACgBc0GAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABa/C/1gzowarvVrAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "üß† Etapa 4: Definir o Discriminador\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dPzMfzINM21e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1, bias=False), # Imagens 1x28x28\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # Adicionado Dropout ap√≥s primeira conv como no original (mas antes n√£o tinha no c√≥digo)\n",
        "            # A√ß√£o: 64 x 14 x 14\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128), # Adicionado BatchNorm para estabilidade\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            # A√ß√£o: 128 x 7 x 7\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Observa√ß√£o: Adicionei bias=False nas camadas convolucionais e BatchNorm2d no Discriminador, que s√£o pr√°ticas comuns em arquiteturas DCGAN e podem ajudar na estabilidade.\n",
        "# O Dropout original foi mantido, embora sua posi√ß√£o possa variar."
      ],
      "metadata": {
        "id": "QfxxP9aIOmAq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "üé® Etapa 5: Definir o Gerador\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KVog0MnTM2wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # Entrada: latent_dim\n",
        "            nn.Linear(latent_dim, 256 * 7 * 7),\n",
        "            # N√£o h√° LeakyReLU/BatchNorm1d na vers√£o original diretamente ap√≥s o Linear antes do Unflatten\n",
        "            # Mas o c√≥digo fornecido tinha. Vou mant√™-lo.\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(256 * 7 * 7),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            # A√ß√£o: 256 x 7 x 7\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), # output 128 x 14 x 14\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # A√ß√£o: 128 x 14 x 14\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),   # output 1 x 28 x 28\n",
        "            nn.Tanh() # Normaliza a sa√≠da para [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "#Observa√ß√£o: Adicionei bias=False nas camadas ConvTranspose2d do Gerador, uma pr√°tica comum em DCGANs quando se usa BatchNorm. A estrutura original do Gerador foi mantida."
      ],
      "metadata": {
        "id": "zLN2fod8O3aP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "‚öôÔ∏è Etapa 6: Inicializar modelos, otimizadores e par√¢metros\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-uIiICvlM2mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "# batch_size definido no DataLoader (64)\n",
        "epochs = 100 # Pode precisar de ajuste; 100 √© um bom come√ßo\n",
        "lr = 0.0002\n",
        "beta1 = 0.5 # Beta1 recomendado para Adam em GANs\n",
        "beta2 = 0.999\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "generator = Generator(latent_dim).to(device)\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ2XDCtTO_8j",
        "outputId": "429700e4-010b-43b6-a97f-e733f8e08da0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa√ß√£o de pesos (opcional, mas pode ajudar)\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "loss_fn = nn.BCELoss() # Binary Cross Entropy Loss\n",
        "\n",
        "real_label = 1.\n",
        "fake_label = 0."
      ],
      "metadata": {
        "id": "h2U2qkdtPCvt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "üîÅ Etapa 7: Treinar a GAN e Visualizar Resultados Parciais\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6lSSVu7JM2bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, real_imgs in enumerate(dataloader):\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "\n",
        "        # --- Treinar o Discriminador ---\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Labels para imagens reais e falsas\n",
        "        labels_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        labels_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
        "\n",
        "        # Perda com imagens reais\n",
        "        output_real = discriminator(real_imgs).view(-1)\n",
        "        loss_real = loss_fn(output_real, labels_real)\n",
        "\n",
        "        # Gerar imagens falsas\n",
        "        noise = torch.randn(b_size, latent_dim, device=device)\n",
        "        fake_imgs = generator(noise)\n",
        "\n",
        "        # Perda com imagens falsas\n",
        "        # Usar .detach() para n√£o calcular gradientes para o gerador aqui\n",
        "        output_fake = discriminator(fake_imgs.detach()).view(-1)\n",
        "        loss_fake = loss_fn(output_fake, labels_fake)\n",
        "\n",
        "        # Perda total do discriminador e otimiza√ß√£o\n",
        "        loss_D = loss_real + loss_fake\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # --- Treinar o Gerador ---\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # O gerador quer que o discriminador pense que as imagens falsas s√£o reais\n",
        "        labels_gen = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        output_gen = discriminator(fake_imgs).view(-1) # N√£o usar .detach() aqui\n",
        "        loss_G = loss_fn(output_gen, labels_gen)\n",
        "\n",
        "        # Perda total do gerador e otimiza√ß√£o\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    # Imprimir perdas ao final de cada √©poca\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}\")\n",
        "\n",
        "    # Gerar e visualizar imagens (a cada 10 √©pocas)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad(): # N√£o calcular gradientes durante a gera√ß√£o de amostras\n",
        "            # Usar um tensor de ru√≠do fixo para ver a evolu√ß√£o das mesmas amostras (opcional)\n",
        "            # test_noise = getattr(generator, 'fixed_noise', torch.randn(16, latent_dim, device=device))\n",
        "            # generator.fixed_noise = test_noise\n",
        "            test_noise = torch.randn(16, latent_dim, device=device) # Ou gerar novo ru√≠do sempre\n",
        "\n",
        "            generated_imgs = generator(test_noise).cpu() # Mover para CPU para matplotlib\n",
        "\n",
        "        # Ajustar visualiza√ß√£o para o formato da imagem de sa√≠da do gerador (1, 28, 28)\n",
        "        # As imagens est√£o em [-1, 1], reescale para [0, 1] para visualiza√ß√£o se necess√°rio ou imshow lida bem.\n",
        "        # generated_imgs = (generated_imgs + 1) / 2 # Opcional: reescalar para [0,1]\n",
        "\n",
        "        fig, axs = plt.subplots(4, 4, figsize=(4, 4))\n",
        "        plt.suptitle(f\"√âpoca {epoch+1}\", y=1.02) # Adicionar t√≠tulo com a √©poca\n",
        "        for k_ax, img_tensor in enumerate(generated_imgs):\n",
        "            row, col = k_ax // 4, k_ax % 4\n",
        "            ax = axs[row, col]\n",
        "            ax.imshow(img_tensor.squeeze().numpy(), cmap='gray') # .squeeze() remove a dimens√£o do canal\n",
        "            ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPr4VI73PNQb",
        "outputId": "1813dd79-9376-493d-bdb3-f084dd03f754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] | Loss_D: 0.3602 | Loss_G: 1.9476\n",
            "Epoch [2/100] | Loss_D: 0.4738 | Loss_G: 1.8353\n",
            "Epoch [3/100] | Loss_D: 0.7217 | Loss_G: 1.5790\n",
            "Epoch [4/100] | Loss_D: 0.8733 | Loss_G: 0.7849\n",
            "Epoch [5/100] | Loss_D: 0.9333 | Loss_G: 1.1432\n",
            "Epoch [6/100] | Loss_D: 1.1028 | Loss_G: 0.9215\n",
            "Epoch [7/100] | Loss_D: 0.8960 | Loss_G: 1.3306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "üíæ Etapa 8: Salvar os modelos (ap√≥s o treinamento)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HFdYB4AZPYPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os pesos dos modelos (state_dict)\n",
        "torch.save(generator.state_dict(), \"generator_digit4.pt\")\n",
        "torch.save(discriminator.state_dict(), \"discriminator_digit4.pt\")\n",
        "\n",
        "print(\"Modelos salvos!\")\n",
        "\n",
        "# Para carregar os modelos posteriormente:\n",
        "# generator = Generator(latent_dim)\n",
        "# generator.load_state_dict(torch.load(\"generator_digit4.pt\"))\n",
        "# discriminator = Discriminator()\n",
        "# discriminator.load_state_dict(torch.load(\"discriminator_digit4.pt\"))\n",
        "# generator.to(device)\n",
        "# discriminator.to(device)\n",
        "# generator.eval() # Para infer√™ncia\n",
        "# discriminator.eval() # Para infer√™ncia"
      ],
      "metadata": {
        "id": "EVXQ_EokPz_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}